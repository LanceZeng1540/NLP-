{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于逻辑回归与词袋模式的文本分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bcb96ba890>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1948,  0.0250, -0.7627,  1.3969, -0.3245],\n",
       "        [ 0.2879,  1.0579,  0.9621,  0.3935,  1.1322]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = nn.Linear(5,3)\n",
    "data = torch.randn(2,5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1755, -0.3268, -0.5069],\n",
       "        [-0.6602,  0.2260,  0.1089]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5404, -2.2102],\n",
      "        [ 2.1130, -0.0040]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(2,2)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3softmax 函数的利用率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-af219f746ed4>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8416, 0.1584],\n",
       "        [0.8925, 0.1075]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0658, 0.0992],\n",
       "        [0.9342, 0.9008]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(data,dim =0)  #dim =0 是对列进行归一，dim = 1是对行进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7214, -2.3107],\n",
       "        [-0.0680, -0.1045]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(data,dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4目标函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#训练数据data-->前向传播(linear relu 层 网络结构)--> y predict-->y truth 损失 loss/交叉熵\n",
    "                                                                            <--反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"me guesta comer en la cafeteria\".split(),\"SPANISH\"),\n",
    "       (\"Give it to me\".split() ,\"ENGLISH\"),\n",
    "        (\"No creo que ssea una buena idea\".split(),\"SPANISH\"),\n",
    "       (\"No it is not a good idea to get lost at sea\",\"ENGLISH\")\n",
    "       ]\n",
    "test_data = [(\"Yo creo que si\".split(),\"SPANISH\"),\n",
    "            (\"it is lost on me \".split(),\"ENGLISH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me', 'guesta', 'comer', 'en', 'la', 'cafeteria']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"me guesta comer en la cafeteria\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'guesta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'ssea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'N': 16, 'o': 17, ' ': 18, 'i': 19, 't': 20, 's': 21, 'n': 22, 'a': 23, 'g': 24, 'd': 25, 'e': 26, 'l': 27, 'Yo': 28, 'si': 29, 'is': 30, 'lost': 31, 'on': 32}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix ={ }\n",
    "for sent,_ in data+test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0924,  0.0512, -0.0503, -0.0191, -0.1674, -0.0830,  0.0945, -0.0423,\n",
      "          0.1734,  0.1395, -0.0082, -0.1162,  0.1060,  0.0540, -0.1125,  0.1131,\n",
      "          0.1057,  0.1544, -0.0976, -0.0287, -0.0034,  0.0254, -0.1321, -0.1235,\n",
      "          0.0947, -0.0408,  0.0850,  0.0099,  0.0572,  0.0383,  0.0633,  0.0863,\n",
      "         -0.1612],\n",
      "        [ 0.0876, -0.1224, -0.1313,  0.0106, -0.0297,  0.1022, -0.1008, -0.1548,\n",
      "          0.1267, -0.0258,  0.0979,  0.0560, -0.1305,  0.0350,  0.0418, -0.1166,\n",
      "         -0.0826,  0.0594,  0.0312, -0.0740, -0.0527,  0.1594, -0.0322,  0.0981,\n",
      "          0.0754, -0.1125, -0.1480,  0.1671,  0.0091,  0.1193,  0.0361,  0.0560,\n",
      "          0.1300]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1651, -0.1155], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE=len(word_to_ix)\n",
    "NUM_LABELS =2\n",
    "model = BoWClassfier(VOCAB_SIZE,NUM_LABELS)\n",
    "for parm in model.parameters():\n",
    "    print(parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassfier(\n",
       "  (linear): Linear(in_features=33, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (linear): Linear(in_features=33, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8348, -0.5691]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    sample = data[0]\n",
    "    bow_vector = make_bow_vector(sample[0],word_to_ix)\n",
    "    log_probs = model(bow_vector)\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2923, -1.3724]])\n",
      "tensor([[-1.6829, -0.2056]])\n",
      "tensor([ 0.4375, -0.4192], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "#模型 训练\n",
    "optimizer = optim.SGD(model.parameters(),lr =0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for instance ,label in data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        bow_vec = make_bow_vector(instance,word_to_ix)\n",
    "        target = make_target(label,label_to_ix)\n",
    "       \n",
    "        log_probs = model(bow_vec)\n",
    "        \n",
    "        loss = loss_function(log_probs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)\n",
    "\n",
    "# 对应西班牙语的指数上升，英语下降！\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2923, -1.3724]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample = test_data[0]\n",
    "    bow_vec = make_bow_vector(sample[0],word_to_ix)\n",
    "    log_probs = model(bow_vec)\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1691,  0.6353,  0.6315,  0.6136,  0.3794,  0.3801, -0.8016, -0.6745,\n",
      "         -0.5228,  0.2348,  0.4375,  0.2484,  0.1811,  0.3078,  0.4451,  0.5064,\n",
      "         -0.2046, -0.5414, -0.9116, -0.1742, -0.4707, -0.1659,  0.0136, -0.3412,\n",
      "         -0.3121, -0.3392, -0.3694, -0.1168, -0.1067,  0.0637,  0.0539, -0.0394,\n",
      "          0.0669],\n",
      "        [ 0.2472, -0.3991, -0.3882, -0.5644, -0.3353, -0.5255,  0.6903,  0.5320,\n",
      "          0.5843, -0.4465, -0.4192, -0.2210, -0.4017, -0.4749, -0.2778, -0.2891,\n",
      "          0.2093,  0.4891,  1.0996,  0.2262,  0.5401,  0.1509,  0.0172,  0.3328,\n",
      "          0.2675,  0.2249,  0.3326,  0.2703,  0.1697,  0.1187,  0.0055, -0.1204,\n",
      "          0.1360]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-901861a90de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'creo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()))[:,word_to_ix['creo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
